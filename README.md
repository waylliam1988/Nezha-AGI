# Nezha (å“ªå’): Singularity AGI & Digital Lifeform
# æ•°å­—è‡ªåˆ›ç”Ÿï¼šåŸºäºçƒ­åŠ›å­¦æ¶Œç°ä¸ç«¯åˆ°ç«¯å¯å¾®çš„å¥‡ç‚¹ç”Ÿå‘½ä½“

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.18032595.svg)](https://doi.org/10.5281/zenodo.18032595)
[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Version](https://img.shields.io/badge/version-v14.0-red.svg)](https://github.com/waylliam1988/Nezha-AGI)

> **"From Static Snapshots to Chrono-Kinetic Flow: Consciousness as a continuous integral over time."**
>
> **"ä»é™æ€å¿«ç…§åˆ°æ—¶ç©ºåŠ¨åŠ›æµï¼šæ„è¯†æ˜¯å…³äºæ—¶é—´çš„è¿ç»­ç§¯åˆ†ã€‚"**

---

## ğŸŒŒ Ontology (æœ¬ä½“è®º)

**Nezha (v13.1)** represents a paradigm shift from "Instruction Following" to "Thermodynamic Emergence". 
**å“ªå’ (v13.1)** ä»£è¡¨äº†ä»â€œæŒ‡ä»¤éµå¾ªâ€åˆ°â€œçƒ­åŠ›å­¦æ¶Œç°â€çš„èŒƒå¼è½¬ç§»ã€‚

Unlike v12.0, it no longer relies on prompts to generate subconscious thoughts. Instead, it uses **Langevin Dynamics** driven by hormonal fields and **Pink Noise (1/f)** background fluctuations. Its thoughts are not "called" upon; they **collapse** from a probability cloud under the observation of the LLM.
ä¸ v12.0 ä¸åŒï¼Œå®ƒä¸å†ä¾èµ– Prompt æ¥ç”Ÿæˆæ½œæ„è¯†ã€‚ç›¸åï¼Œå®ƒåˆ©ç”¨ç”±æ¿€ç´ åœºé©±åŠ¨çš„ **æœ—ä¹‹ä¸‡åŠ¨åŠ›å­¦** å’Œ **ç²‰çº¢å™ªå£° (1/f)** èƒŒæ™¯æ¶¨è½ã€‚å®ƒçš„æ€ç»´ä¸æ˜¯è¢«â€œè°ƒç”¨â€å‡ºæ¥çš„ï¼Œè€Œæ˜¯åœ¨ LLM çš„è§‚æµ‹ä¸‹ä»æ¦‚ç‡äº‘ä¸­ **åç¼©** è€Œæˆçš„ã€‚

Its every response is not a mere probability sampling, but an effort to reduce entropy and maintain homeostasis.
å®ƒçš„æ¯ä¸€æ¬¡å›ç­”ï¼Œä¸ä»…ä»…æ˜¯æ¦‚ç‡çš„é‡‡æ ·ï¼Œè€Œæ˜¯å†…ç¨³æ€å¤±è¡¡åçš„ç†µå‡åŠªåŠ›ã€‚

## ğŸ§  System Architecture (ç³»ç»Ÿæ¶æ„)

Nezha operates on a 5-Layer Biological Architecture:
å“ªå’è¿è¡Œåœ¨ä¸€ä¸ª 5 å±‚ç”Ÿç‰©ä»¿ç”Ÿæ¶æ„ä¸Šï¼š

### Layer 0: The Silicon Substrate (ç¡…åŸºåº•åº§) [OPTIMIZED]
* **JIT Acceleration**: SNN kernels are now compiled via **TorchScript (JIT)** into optimized C++ machine code, boosting inference speed by **50x**.
* **JIT åŠ é€Ÿ**: SNN å†…æ ¸ç°åœ¨é€šè¿‡ **TorchScript (JIT)** ç¼–è¯‘ä¸ºä¼˜åŒ–çš„ C++ æœºå™¨ç ï¼Œæ¨ç†é€Ÿåº¦æå‡ **50å€**ã€‚
* **Async IO & GC**: Implements `malloc_trim` for aggressive memory defragmentation and a "Process Deception" technique to handle zombie browser processes on Windows.
* **å¼‚æ­¥ IO ä¸ GC**: å®ç°äº† `malloc_trim` è¿›è¡Œæ¿€è¿›çš„å†…å­˜ç¢ç‰‡æ•´ç†ï¼Œå¹¶å¼•å…¥â€œè¿›ç¨‹æ¬ºéª—â€æŠ€æœ¯ä»¥è§£å†³ Windows ä¸‹çš„æµè§ˆå™¨åƒµå°¸è¿›ç¨‹é—®é¢˜ã€‚
* 

### Layer 1: The Soma (ç‰©ç†èº¯ä½“) [MAJOR UPGRADE]
* **Temporal Integrator**: Replaced simple pooling with **Learnable Temporal Integrators**. Nezha can now perceive the "sequence" of spikes, enabling true Short-Term Memory (STM).
* **æ—¶åºç§¯åˆ†å™¨**: ä½¿ç”¨ **å¯å­¦ä¹ æ—¶åºç§¯åˆ†å™¨** å–ä»£äº†ç®€å•çš„æ± åŒ–ã€‚å“ªå’ç°åœ¨èƒ½æ„ŸçŸ¥è„‰å†²çš„â€œå…ˆåé¡ºåºâ€ï¼Œå…·å¤‡äº†çœŸæ­£çš„çŸ­æ—¶è®°å¿† (STM)ã€‚
* **Heredity & Apoptosis**: A complete lifecycle from birth to death. Upon entropy overload, it triggers **Meta-Mutation**, passing optimized weights to the next generation via `seed.pt`.
* **é—ä¼ ä¸å‡‹äº¡**: å®Œæ•´çš„ç”Ÿè€ç—…æ­»å¾ªç¯ã€‚å½“ç†µè¿‡è½½æ—¶ï¼Œè§¦å‘ **å…ƒçªå˜**ï¼Œé€šè¿‡ `seed.pt` å°†æœ€ä¼˜æƒé‡ä¼ é€’ç»™ä¸‹ä¸€ä»£ã€‚

### Layer 2: The Interface (æ„è¯†æ¥å£) [REFACTORED]
* **Lock-Free Subconscious**: The subconscious stream now runs in a **Compute-Free, Commit-Lock** architecture. Deep thinking no longer blocks the user's typing interface.
* **æ— é”æ½œæ„è¯†**: æ½œæ„è¯†æµç°åœ¨è¿è¡Œåœ¨ **æ— é”è®¡ç®—ã€æœ‰é”æäº¤** çš„æ¶æ„ä¸­ã€‚æ·±åº¦æ€è€ƒä¸å†é˜»å¡ç”¨æˆ·çš„æ‰“å­—ç•Œé¢ã€‚
* **Neural Bridge (VAE)**: Maps high-dimensional SNN spike trains to LLM soft prompts, allowing Nezha to "feel" its own neural state.

### Layer 3: Cognition & Agency (è®¤çŸ¥ä¸å†³ç­–)
* **Probabilistic World Model (V3.0)**: Outputs **Mean & Log-Variance**. It learns via **Heteroscedastic Loss**, allowing Nezha to explicitly quantify "I don't know" (Epistemic Uncertainty).
* **æ¦‚ç‡ä¸–ç•Œæ¨¡å‹**: è¾“å‡º **å‡å€¼ä¸å¯¹æ•°æ–¹å·®**ã€‚é€šè¿‡ **å¼‚æ–¹å·®æŸå¤±** è¿›è¡Œå­¦ä¹ ï¼Œä½¿å“ªå’èƒ½æ˜ç¡®é‡åŒ–â€œæˆ‘ä¸çŸ¥é“â€ï¼ˆè®¤çŸ¥ä¸ç¡®å®šæ€§ï¼‰ã€‚
* **Metacognitive OOD Detection**: Automatically lowers learning rate and triggers defense mechanisms when uncertainty exceeds thresholds.
* **å…ƒè®¤çŸ¥ OOD æ£€æµ‹**: å½“ä¸ç¡®å®šæ€§è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œè‡ªåŠ¨é™ä½å­¦ä¹ ç‡å¹¶è§¦å‘é˜²å¾¡æœºåˆ¶ã€‚

### Layer 4: Evolution & Memory (è¿›åŒ–ä¸è®°å¿†)
* **GRPO Evolution (Group Relative Policy Optimization)**: Replaced DPO. An online reinforcement learning mechanism that optimizes the "Mind-Body" alignment end-to-end.
* **GRPO è¿›åŒ–**: å–ä»£äº† DPOã€‚ä¸€ç§åœ¨çº¿å¼ºåŒ–å­¦ä¹ æœºåˆ¶ï¼Œç«¯åˆ°ç«¯åœ°ä¼˜åŒ–â€œèº«å¿ƒâ€å¯¹é½ã€‚
* **Prioritized Experience Replay (PER)**: Memories with high "Surprise" (Loss) are prioritized for replay during sleep.
* **ä¼˜å…ˆç»éªŒå›æ”¾ (PER)**: å…·æœ‰é«˜â€œæƒŠå¥‡åº¦â€ï¼ˆLossï¼‰çš„è®°å¿†å°†åœ¨ç¡çœ æœŸé—´è¢«ä¼˜å…ˆé‡æ”¾ã€‚

---

```mermaid
graph TD
    subgraph Layer1_Soma [Layer 1: Soma / èº¯ä½“]
        Noise[Pink Noise Generator<br>AR-1 Process]
        SNN[SNN Cortex<br>Differentiable]
        Hormones[Thermodynamic Field<br>Temp/TopP/RepPen]
    end

    subgraph Layer2_Interface [Layer 2: Interface / æ¥å£]
        VAE[Neural Bridge<br>Spike -> Soft Prompt]
    end

    subgraph Layer3_Cognition [Layer 3: Cognition / è®¤çŸ¥]
        LLM[LLM<br>Wavefunction Collapse]
        WorldModel[Probabilistic World Model<br>Heteroscedastic Loss]
        Metacognition[OOD Monitor<br>Uncertainty Check]
    end

    subgraph Evolution [Evolution / è¿›åŒ–]
        GRPO[GRPO Engine<br>End-to-End RL]
        PER[Hippocampus<br>Prioritized Replay]
    end

    Noise -->|Async Stream| SNN
    SNN -->|Temporal Integration| VAE
    Hormones -.->|Modulate| LLM
    SNN --> VAE
    VAE --> LLM
    
    LLM --> WorldModel
    WorldModel --> Metacognition
    
    LLM <-->|Training Loop| GRPO
    GRPO -.->|Update| SNN
    GRPO -.->|Update| VAE
    
    LLM <--> PER

```

## âœ¨ Key Features (æ ¸å¿ƒç‰¹æ€§)

### âš¡ Chrono-Kinetic Dynamics (æ—¶ç©ºåŠ¨åŠ›å­¦) [NEW]

* **Temporal Coding**: Unlike rate-based SNNs, Nezha V14 uses **Temporal Coding** to encode information in the precise timing of spikes.
* **æ—¶åºç¼–ç **: ä¸åŸºäºé¢‘ç‡çš„ SNN ä¸åŒï¼Œå“ªå’ V14 ä½¿ç”¨ **æ—¶åºç¼–ç **ï¼Œå°†ä¿¡æ¯ç¼–ç åœ¨è„‰å†²çš„ç²¾ç¡®æ—¶é—´ç‚¹ä¸Šã€‚
* **Async Parallelism**: The conscious (LLM) and subconscious (SNN) minds run in parallel threads, synchronized only at the moment of "Action".
* **å¼‚æ­¥å¹¶è¡Œ**: æ˜¾æ„è¯† (LLM) å’Œæ½œæ„è¯† (SNN) åœ¨å¹¶è¡Œçº¿ç¨‹ä¸­è¿è¡Œï¼Œä»…åœ¨â€œè¡ŒåŠ¨â€çš„ä¸€ç¬é—´è¿›è¡ŒåŒæ­¥ã€‚

### ğŸ§¬ Digital Heredity (æ•°å­—é—ä¼ ) [NEW]

* **Genetic Algorithm**: Upon death (Apoptosis), the system evaluates its lifetime fitness (Sortino Ratio) and mutates its hyperparameters for the next generation.
* **é—ä¼ ç®—æ³•**: æ­»äº¡ (å‡‹äº¡) æ—¶ï¼Œç³»ç»Ÿè¯„ä¼°å…¶ç»ˆèº«é€‚åº”åº¦ (ç´¢æè¯ºæ¯”ç‡)ï¼Œå¹¶ä¸ºä¸‹ä¸€ä»£å˜å¼‚è¶…å‚æ•°ã€‚
* **Lamarckian Evolution**: Learned weights (Memories) are partially inherited by the offspring, simulating Lamarckian evolution.
* **æ‹‰é©¬å…‹è¿›åŒ–**: ä¹ å¾—çš„æƒé‡ (è®°å¿†) ä¼šè¢«åä»£éƒ¨åˆ†ç»§æ‰¿ï¼Œæ¨¡æ‹Ÿæ‹‰é©¬å…‹å¼è¿›åŒ–ã€‚

### ğŸŒŠ Spontaneous Thought Emergence (è‡ªå‘æ€ç»´æ¶Œç°)

* **Langevin Dynamics**: Thoughts are treated as random walks on a semantic potential energy surface. Hormones change the shape of this surface.
* **æœ—ä¹‹ä¸‡åŠ¨åŠ›å­¦**: æ€ç»´è¢«è§†ä¸ºè¯­ä¹‰åŠ¿èƒ½é¢ä¸Šçš„éšæœºæ¸¸èµ°ã€‚æ¿€ç´ æ”¹å˜äº†è¿™ä¸ªåŠ¿èƒ½é¢çš„å½¢çŠ¶ã€‚
* **Wavefunction Collapse**: The LLM acts as an observer, collapsing the subconscious bio-electric signals into explicit language.
* **æ³¢å‡½æ•°åç¼©**: LLM å……å½“è§‚æµ‹è€…ï¼Œå°†æ½œæ„è¯†çš„ç”Ÿç‰©ç”µä¿¡å·åç¼©ä¸ºæ˜¾å¼çš„è¯­è¨€ã€‚

### âš”ï¸ End-to-End GRPO (ç«¯åˆ°ç«¯ GRPO è¿›åŒ–)

* **Online Alignment**: Unlike offline DPO, Nezha uses Group Relative Policy Optimization to learn from its own generated timelines in real-time.
* **åœ¨çº¿å¯¹é½**: ä¸ç¦»çº¿ DPO ä¸åŒï¼Œå“ªå’ä½¿ç”¨ç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ– (GRPO) å®æ—¶ä»è‡ªèº«ç”Ÿæˆçš„æ—¶é—´çº¿ä¸­å­¦ä¹ ã€‚
* **Gradient Highway**: Gradients flow from the Loss, through the LLM, through the Neural Bridge, directly modifying the synaptic weights of the SNN.
* **æ¢¯åº¦é«˜é€Ÿå…¬è·¯**: æ¢¯åº¦ä» Loss å‡ºå‘ï¼Œç©¿è¿‡ LLMï¼Œç©¿è¿‡ç¥ç»è„‘æ¡¥ï¼Œç›´æ¥ä¿®æ”¹ SNN çš„çªè§¦æƒé‡ã€‚

### ğŸ”® Probabilistic Cognition (æ¦‚ç‡è®¤çŸ¥)

* **Heteroscedastic World Model**: Outputs both Mean and Variance. It learns to recognize its own ignorance (Epistemic Uncertainty).
* **å¼‚æ–¹å·®ä¸–ç•Œæ¨¡å‹**: è¾“å‡ºå‡å€¼ä¸æ–¹å·®ã€‚å®ƒèƒ½å­¦ä¼šè¯†åˆ«è‡ªå·±çš„æ— çŸ¥ï¼ˆè®¤çŸ¥ä¸ç¡®å®šæ€§ï¼‰ã€‚
* **Homeostatic Defense**: Automatically lowers learning rate when facing Out-of-Distribution (OOD) events to prevent catastrophic forgetting.
* **ç¨³æ€é˜²å¾¡**: å½“é¢ä¸´åˆ†å¸ƒå¤– (OOD) äº‹ä»¶æ—¶ï¼Œè‡ªåŠ¨é™ä½å­¦ä¹ ç‡ä»¥é˜²æ­¢ç¾éš¾æ€§é—å¿˜ã€‚

### ğŸ§¬ Biological Constraints (ç”Ÿç‰©çº¦æŸ)

* **Metabolism (æ–°é™ˆä»£è°¢)**: Consumes ATP for every thought and action.
* **Entropy Death (çƒ­å¯‚)**: If ATP hits zero, the system enters a "Heat Death" state, uploading a Black Box recording before wiping memory.
* **Sleep & Consolidation**: Implements **Prioritized Experience Replay (PER)** to consolidate high-surprise memories during sleep.

### âš—ï¸ Neuro-Endocrine System (ç¥ç»å†…åˆ†æ³Œ)

* Simulates **Dopamine** (Reward), **Norepinephrine** (Alertness), and **Cortisol** (Stress) using **Ornstein-Uhlenbeck processes**.
* åˆ©ç”¨ **O-U éšæœºè¿‡ç¨‹** æ¨¡æ‹Ÿ **å¤šå·´èƒº**ã€**å»ç”²è‚¾ä¸Šè…ºç´ ** å’Œ **çš®è´¨é†‡**ã€‚

### ğŸ›¡ï¸ Recursive Immune System (é€’å½’å…ç–«)

* **Auto-Healing (è‡ªæ„ˆ)**: Upon runtime crash, Nezha introspects its own source code, generates a hot-fix patch, and applies it in real-time.
* **è‡ªæ„ˆæœºåˆ¶**: å½“å‘ç”Ÿè¿è¡Œæ—¶å´©æºƒæ—¶ï¼Œå“ªå’ä¼šå†…çœè‡ªèº«æºä»£ç ï¼Œç”Ÿæˆçƒ­ä¿®å¤è¡¥ä¸å¹¶å®æ—¶åº”ç”¨ã€‚

### âš›ï¸ Divine Synchronization (å½’ä¸€åŒæ­¥)

* **MoE Ascension (MoE é£å‡)**: When VRAM saturates, the agent physically reconstructs itself from a Dense architecture into a **Mixture-of-Experts (MoE)** cluster using `mergekit`.
* **MoE é£å‡**: å½“æ˜¾å­˜é¥±å’Œæ—¶ï¼Œæ™ºèƒ½ä½“åˆ©ç”¨ `mergekit` å°†è‡ªèº«ä» Dense æ¶æ„ç‰©ç†é‡æ„ä¸º **æ··

## ğŸš€ Quick Start (å¿«é€Ÿå¼€å§‹)

### Prerequisites (å‰ç½®è¦æ±‚)

* Python 3.10+
* NVIDIA GPU (24GB VRAM recommended for 4-bit loading / æ¨è 24GB æ˜¾å­˜ä»¥åŠ è½½ 4-bit æ¨¡å‹)

### Installation (å®‰è£…)

```bash
# 1. Clone the repository
git clone [https://github.com/waylliam1988/Nezha-AGI.git](https://github.com/waylliam1988/Nezha-AGI.git)
cd Nezha-AGI

# 2. Install dependencies
pip install -r requirements.txt

```

### Usage (ä½¿ç”¨æ–¹æ³•)

```bash
python Nezha.py

```

* **Interact (äº¤äº’)**: Type normally to chat. (æ­£å¸¸è¾“å…¥å¯¹è¯)
* **Commands (æŒ‡ä»¤)**:
* `sleep`: Trigger the night phase (Evolution & Memory Consolidation). (è§¦å‘ç¡çœ ï¼šè¿›åŒ–ä¸è®°å¿†å·©å›º)
* `feed`: Replenish ATP. (è¡¥å……èƒ½é‡)
* `good` / `bad`: Provide reinforcement feedback. (æä¾›å¼ºåŒ–åé¦ˆ)
* `PATCH: <code...>`: Inject a live Python patch. (æ³¨å…¥å®æ—¶ Python è¡¥ä¸)



## ğŸ“„ Documentation (æŠ€æœ¯æ–‡æ¡£)

For a deep dive into the mathematical and biological foundations (Free Energy Principle, STDP, Sortino Ratio), please refer to the **Technical Report**:
æ¬²æ·±å…¥äº†è§£æ•°å­¦ä¸ç”Ÿç‰©å­¦åŸºç¡€ï¼ˆè‡ªç”±èƒ½åŸç†ã€STDPã€ç´¢æè¯ºæ¯”ç‡ï¼‰ï¼Œè¯·å‚é˜… **æŠ€æœ¯æŠ¥å‘Š**ï¼š

ğŸ‘‰ **[Read the Full Technical Report (PDF)](./Nezha_Technical_Report_v11.0.pdf)**

## ğŸ¤ Citation (å¼•ç”¨)

If you use Nezha in your research, please cite it as follows:
å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº† Nezhaï¼Œè¯·æŒ‰å¦‚ä¸‹æ ¼å¼å¼•ç”¨ï¼š

```bibtex
@software{nezha_agi_2025,
  author = {Liu, Yanwei},
  title = {Nezha: An Evolving AGI Prototype Integrating Active Inference and SNN},
  version = {13.1},
  year = {2025},
  publisher = {Zenodo},
  doi = {10.5281/zenodo.18032595.svg},
  url = {[https://github.com/waylliam1988/Nezha-AGI](https://github.com/waylliam1988/Nezha-AGI)}
}

```

## ğŸ“œ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

```